{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eecb600-9ded-4162-a889-844595d5d53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  |   | O\n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  |   | O\n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  |   | O\n",
      "---------\n",
      "O | X |  \n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  |   | O\n",
      "---------\n",
      "O | X | X\n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  | O | O\n",
      "---------\n",
      "O | X | X\n",
      "---------\n",
      "  | X |  \n",
      "---------\n",
      "  | O | O\n",
      "---------\n",
      "O | X | X\n",
      "---------\n",
      "  | X | X\n",
      "---------\n",
      "  | O | O\n",
      "---------\n",
      "O | X | X\n",
      "---------\n",
      "O | X | X\n",
      "---------\n",
      "Agent wins!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.board.fill(0)\n",
    "        self.current_player = 1\n",
    "        return self.board\n",
    "\n",
    "    def is_winner(self, player):\n",
    "        return any(np.all(line == player) for line in np.vstack((self.board, self.board.T, [np.diag(self.board), np.diag(np.fliplr(self.board))])))\n",
    "\n",
    "    def is_draw(self):\n",
    "        return not np.any(self.board == 0)\n",
    "\n",
    "    def available_actions(self):\n",
    "        return list(zip(*np.where(self.board == 0)))\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.board[action] != 0: raise ValueError(\"Invalid action!\")\n",
    "        self.board[action] = self.current_player\n",
    "        if self.is_winner(self.current_player): return self.board, 1\n",
    "        if self.is_draw(): return self.board, 0\n",
    "        self.current_player *= -1\n",
    "        return self.board, None\n",
    "\n",
    "    def render(self):\n",
    "        symbols = {1: 'X', -1: 'O', 0: ' '}\n",
    "        for row in self.board: print(\" | \".join(symbols[cell] for cell in row)); print(\"-\" * 9)\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, lr=0.1, discount=0.9, explore=1.0, decay=0.99):\n",
    "        self.q_table = {}\n",
    "        self.lr, self.discount, self.explore, self.decay = lr, discount, explore, decay\n",
    "\n",
    "    def get_q(self, state, action):\n",
    "        return self.q_table.get((state.tobytes(), action), 0)\n",
    "\n",
    "    def update_q(self, state, action, reward, next_state):\n",
    "        current_q = self.get_q(state, action)\n",
    "        max_next_q = max([self.get_q(next_state, a) for a in TicTacToe().available_actions()] or [0])\n",
    "        self.q_table[(state.tobytes(), action)] = current_q + self.lr * (reward + self.discount * max_next_q - current_q)\n",
    "\n",
    "    def select_action(self, state, actions):\n",
    "        if random.random() < self.explore: return random.choice(actions)\n",
    "        q_values = [self.get_q(state, a) for a in actions]\n",
    "        return random.choice([a for a, q in zip(actions, q_values) if q == max(q_values)])\n",
    "\n",
    "    def decay_explore(self):\n",
    "        self.explore *= self.decay\n",
    "\n",
    "def train(agent, episodes=10000):\n",
    "    game = TicTacToe()\n",
    "    for _ in range(episodes):\n",
    "        state, done = game.reset(), False\n",
    "        while not done:\n",
    "            action = agent.select_action(state, game.available_actions())\n",
    "            next_state, reward = game.step(action)\n",
    "            agent.update_q(state, action, reward or 0, next_state)\n",
    "            state, done = next_state, reward is not None\n",
    "        agent.decay_explore()\n",
    "\n",
    "def test(agent):\n",
    "    game, state, done = TicTacToe(), TicTacToe().reset(), False\n",
    "    while not done:\n",
    "        game.render()\n",
    "        action = agent.select_action(state, game.available_actions())\n",
    "        state, reward = game.step(action)\n",
    "        done = reward is not None\n",
    "        if reward == 1: print(\"Agent wins!\")\n",
    "        elif reward == 0: print(\"It's a draw!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent = QLearningAgent()\n",
    "    train(agent, episodes=10000)\n",
    "    test(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8281e62d-9e11-4f51-88b8-be32cb5e4da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
